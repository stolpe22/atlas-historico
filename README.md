# ğŸŒ Atlas HistÃ³rico

O Atlas HistÃ³rico Ã© uma plataforma geogrÃ¡fica interativa de cÃ³digo aberto projetada para consolidar, visualizar e gerenciar cronologias histÃ³ricas mundiais. Combinando o poder de bancos de dados geoespaciais com uma interface dinÃ¢mica, o projeto permite que usuÃ¡rios explorem eventos atravÃ©s do tempo e do espaÃ§o.

## ğŸ“– Ãndice
- [VisÃ£o Geral e PropÃ³sito](#-visÃ£o-geral-e-propÃ³sito)
- [Arquitetura de Software](#-arquitetura-de-software)
  - [Frontend: Data-Driven Design](#frontend-data-driven-design)
  - [Backend: Motor de ETL Unificado](#backend-motor-de-etl-unificado)
- [Stack TecnolÃ³gica](#-stack-tecnolÃ³gica)
- [Obter o CÃ³digo](#-obter-o-cÃ³digo) <!-- antes de instalaÃ§Ã£o -->
- [InstalaÃ§Ã£o e ConfiguraÃ§Ã£o](#-instalaÃ§Ã£o-e-configuraÃ§Ã£o)
  - [Via Docker (Recomendado)](#via-docker-recomendado)
  - [ExecuÃ§Ã£o Manual (Desenvolvimento)](#execuÃ§Ã£o-manual-desenvolvimento)
- [Guia do Desenvolvedor: Expandindo o Projeto](#-guia-do-desenvolvedor-expandindo-o-projeto)
- [Funcionalidades Principais](#-funcionalidades-principais)
- [Estrutura de Pastas](#-estrutura-de-pastas)
- [VariÃ¡veis de Ambiente](#-variÃ¡veis-de-ambiente)

## ğŸ¯ VisÃ£o Geral e PropÃ³sito
Muitos dados histÃ³ricos estÃ£o dispersos em arquivos CSV, bancos de dados legados ou APIs complexas. O Atlas HistÃ³rico foi construÃ­do para resolver este problema, estabelecendo a infraestrutura fundamental de um Agregador GeogrÃ¡fico.

Embora o projeto esteja em estÃ¡gio inicial de populaÃ§Ã£o â€” contando atualmente com uma base semente curada (presets locais) e capacidade de importaÃ§Ã£o de datasets do Kaggle â€” sua arquitetura foi desenhada para escalar. A plataforma oferece uma interface unificada onde dados sÃ£o normalizados e enriquecidos automaticamente. Diferente de mapas simples, o projeto utiliza inteligÃªncia espacial para deduzir informaÃ§Ãµes geogrÃ¡ficas (como continentes) a partir de coordenadas puras, preenchendo lacunas comuns em datasets brutos e preparando o terreno para integrar fontes massivas como a Wikidata no futuro.

## ğŸ—ï¸ Arquitetura de Software

### Frontend: Data-Driven Design
A interface nÃ£o Ã© apenas um conjunto de pÃ¡ginas, mas um sistema reativo que responde a metadados e gerencia processos complexos de longa duraÃ§Ã£o.
- **ConfiguraÃ§Ã£o via Constantes:** Os formulÃ¡rios de importaÃ§Ã£o sÃ£o gerados dinamicamente baseados na `ADAPTER_UI_CONFIG`. Adicionar um novo campo de input nÃ£o requer alteraÃ§Ã£o no JSX.
- **Gerenciamento de Estado Persistente (Multi-Tasking):** O `ETLContext` suporta mÃºltiplas tarefas simultÃ¢neas. O estado de cada processo (ImportaÃ§Ã£o CSV, SincronizaÃ§Ã£o GeoNames) Ã© salvo no `localStorage`.
- **ResiliÃªncia ao Refresh (F5):** Se o usuÃ¡rio recarregar a pÃ¡gina durante uma importaÃ§Ã£o, o frontend recupera os `taskIds`, reconecta-se ao backend e retoma a exibiÃ§Ã£o dos logs em tempo real sem perder o contexto.
- **VisualizaÃ§Ã£o de Alta Performance:** ImplementaÃ§Ã£o de Leaflet Marker Clustering com carregamento fragmentado, garantindo fluidez (60fps) no mapa.

### Backend: Motor de ETL Unificado
O backend utiliza o Registry Pattern para gerenciar integraÃ§Ãµes. Existe um endpoint mestre (`/etl/run`) que despacha comandos para adaptadores especializados.
- **Adaptadores PolimÃ³rficos:** A lÃ³gica de extraÃ§Ã£o Ã© isolada. Atualmente suporta Kaggle e Seed (JSON local), com estrutura pronta para implementaÃ§Ã£o de novos robÃ´s.
- **Geocoding & Geofencing (PostGIS):** O sistema utiliza a extensÃ£o espacial do PostgreSQL para realizar operaÃ§Ãµes geomÃ©tricas avanÃ§adas.
  - **DetecÃ§Ã£o AutomÃ¡tica:** O sistema carrega multipolÃ­gonos de continentes (fonte: `hrbrmstr/continents.json`) e utiliza a funÃ§Ã£o `ST_Intersects` para identificar automaticamente em qual continente um evento ocorreu, enriquecendo o dado bruto.
- **TaskManager Singleton:** Gerencia threads em background, permitindo logs granulares e cancelamento gracioso de tarefas.

## ğŸ› ï¸ Stack TecnolÃ³gica

### Frontend
| Tecnologia              | DescriÃ§Ã£o                                                    |
|-------------------------|--------------------------------------------------------------|
| React 18 (Vite)         | Framework principal para SPA de alta performance.            |
| Tailwind CSS            | EstilizaÃ§Ã£o utilitÃ¡ria com suporte nativo a Dark Mode.       |
| Leaflet & React-Leaflet | Biblioteca de mapas open-source para renderizaÃ§Ã£o de clusters. |
| Lucide React            | Conjunto de Ã­cones vetoriais modernos.                       |

### Backend
| Tecnologia               | DescriÃ§Ã£o                                                    |
|--------------------------|--------------------------------------------------------------|
| FastAPI                  | Framework Python assÃ­ncrono e tipado.                        |
| UV                       | Gerenciador de pacotes Python ultra-rÃ¡pido (substituto do Pip). |
| SQLAlchemy 2.0           | ORM moderno para interaÃ§Ã£o com o banco.                      |
| PostgreSQL 16 + PostGIS  | Banco de dados relacional com motor espacial SIG.            |

## ğŸ“¥ Obter o CÃ³digo
RepositÃ³rio oficial: https://github.com/stolpe22/atlas-historico

- **Clonar via Git**
```bash
git clone https://github.com/stolpe22/atlas-historico.git
cd atlas-historico
```

- **Baixar ZIP**
  1) Acesse a pÃ¡gina do repositÃ³rio: https://github.com/stolpe22/atlas-historico  
  2) Clique em **Code** > **Download ZIP**  
  3) Extraia o arquivo em seu diretÃ³rio de preferÃªncia

## ğŸ“¦ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### Via Docker (Recomendado)
A forma mais rÃ¡pida de subir o ambiente completo (Front, Back, DB e Tradutor).

1. Certifique-se de ter o Docker e Docker Compose instalados.
2. Na raiz do projeto, escolha um dos caminhos:
   - **Script de conveniÃªncia**
     ```bash
     chmod +x run.sh
     ./run.sh
     ```
   - **Comando direto**
     ```bash
     docker-compose up --build
     ```
3. Acesse as URLs:
   - Frontend: http://localhost:3000
   - Backend (Docs): http://localhost:8000/docs
   - TraduÃ§Ã£o (LibreTranslate): http://localhost:5000

### ExecuÃ§Ã£o Manual (Desenvolvimento)
Caso deseje rodar os serviÃ§os fora do Docker para depuraÃ§Ã£o:

1. **Banco de Dados** â€” VocÃª precisarÃ¡ de um PostgreSQL com PostGIS ativo.
```sql
CREATE DATABASE history_atlas;
CREATE EXTENSION postgis;
```

2. **Backend** â€” Navegue atÃ© a pasta `/backend`:
```bash
# Instale o UV se nÃ£o tiver
curl -LsSf https://astral.sh/uv/install.sh | sh

# Sincronize dependÃªncias e ative venv
uv sync
source .venv/bin/activate

# Rode o servidor
uvicorn app.main:app --reload --port 8000
```

3. **Frontend** â€” Navegue atÃ© a pasta `/frontend`:
```bash
npm install
npm run dev -- --port 3000
```
> Nota: Configure a variÃ¡vel `VITE_API_URL` no seu `.env` se necessÃ¡rio.

## ğŸ§­ Guia do Desenvolvedor: Expandindo o Projeto

### Adicionando Novos Modais de ImportaÃ§Ã£o
Para adicionar uma nova fonte de dados no Frontend, edite `projeto/components/modals/ETLModal.jsx` e adicione Ã  constante `ADAPTER_UI_CONFIG`. O formulÃ¡rio serÃ¡ gerado automaticamente.

### Criando um Novo Adaptador ETL
1. Crie um novo arquivo em `app/etl/nome_da_api/adapter.py`.
2. Herde de `BaseEtlAdapter`.
3. Implemente a lÃ³gica de `run`.
4. Registre no `app/etl/registry.py`.

```python
# app/etl/exemplo/adapter.py
from ..base import BaseEtlAdapter
from ...services.task_manager import task_manager

class ExemploAdapter(BaseEtlAdapter):
    def run(self, db, task_id, credentials, params):
        task_manager.log(task_id, "Iniciando processo...")
        # LÃ³gica de extraÃ§Ã£o aqui
        return "Sucesso"
```

## ğŸ—ºï¸ Funcionalidades Principais
- Filtro Temporal DinÃ¢mico: Explore desde a PrÃ©-HistÃ³ria atÃ© a Idade ContemporÃ¢nea usando o Slider de datas.
- ImportaÃ§Ã£o Kaggle: Conecte sua conta do Kaggle e importe datasets massivos de CSV para o banco PostGIS.
- Geofencing AutomÃ¡tico: Utiliza multipolÃ­gonos de continentes para identificar automaticamente a regiÃ£o geogrÃ¡fica de qualquer coordenada inserida, garantindo consistÃªncia nos filtros.
- RestauraÃ§Ã£o Local (Seed): Recupere rapidamente os dados bÃ¡sicos ("seed data") do projeto a partir do `manual_events.json`.
- Geonames Offline: Sincronize milhares de cidades para o seu banco local para garantir geolocalizaÃ§Ã£o rÃ¡pida.
- TraduÃ§Ã£o EN/PT: TraduÃ§Ã£o de conteÃºdos histÃ³ricos em tempo real via LibreTranslate.

## ğŸ“‚ Estrutura de Pastas
```
atlas-historico/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ etl/            # Adaptadores e lÃ³gica de carga (Kaggle, Seed)
â”‚   â”‚   â”œâ”€â”€ models/         # Modelos SQLAlchemy e PostGIS (Geometry)
â”‚   â”‚   â”œâ”€â”€ routes/         # Endpoints FastAPI
â”‚   â”‚   â””â”€â”€ services/       # TaskManager, EventService
â”‚   â”œâ”€â”€ docs/               # Markdown de ajuda servido pela API
â”‚   â””â”€â”€ Dockerfile          # Build com gerenciador UV
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # Componentes React (Map, Modals, Layout)
â”‚   â”‚   â”œâ”€â”€ context/        # Gerenciamento de Estado (ETLContext, Toast)
â”‚   â”‚   â”œâ”€â”€ hooks/          # Hooks customizados (useEvents, useTheme)
â”‚   â”‚   â””â”€â”€ pages/          # MainPage, SettingsPage
â”‚   â””â”€â”€ Dockerfile          # Build multi-stage Nginx
â”œâ”€â”€ docker-compose.yaml     # Orquestrador de serviÃ§os
â””â”€â”€ run.sh                  # Script de bootstrap (Build + Up)
```

## ğŸ” VariÃ¡veis de Ambiente
O backend utiliza o arquivo `.env` (ou variÃ¡veis injetadas via Docker Compose):

| VariÃ¡vel         | DescriÃ§Ã£o                                 | PadrÃ£o                  |
|------------------|-------------------------------------------|-------------------------|
| DB_HOST          | Host do banco de dados                    | db (docker) ou localhost |
| DB_NAME          | Nome do banco                             | history_atlas           |
| WIKIDATA_TIMEOUT | Timeout para queries SPARQL               | 120                     |
| QUERY_LIMIT      | Limite de eventos por extraÃ§Ã£o            | 500                     |
| VITE_API_URL     | URL da API para o Frontend                | http://localhost:8000   |

---

Atlas HistÃ³rico â€” Criado por @stolpe22