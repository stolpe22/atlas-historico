import kagglehub
import pandas as pd
import os
import glob
from sqlalchemy.orm import Session
from app.models import KaggleDataset, KaggleStaging
from .auth import configure_kaggle_env

def extract_and_load_staging(db: Session, kaggle_dataset_id: str):
    """
    Baixa o CSV e salva no Staging.
    TRAVA: Se jÃ¡ existir no banco, pula o download.
    """
    # 1. VERIFICAÃ‡ÃƒO INTELIGENTE (AQUI Ã‰ A MUDANÃ‡A)
    existing_dataset = db.query(KaggleDataset).filter(
        KaggleDataset.kaggle_id == kaggle_dataset_id
    ).first()

    # Se jÃ¡ existe e tem dados, nÃ£o baixa de novo!
    if existing_dataset and existing_dataset.record_count > 0:
        print(f"ğŸ“¦ Dataset jÃ¡ carregado ({existing_dataset.record_count} registros). Pulando download.")
        return existing_dataset.id

    # --- Se nÃ£o existe, segue o fluxo normal de download ---
    
    configure_kaggle_env(db)
    print(f"â¬‡ï¸  Baixando dataset do Kaggle: {kaggle_dataset_id}...")
    
    try:
        path = kagglehub.dataset_download(kaggle_dataset_id)
        print(f"ğŸ“‚ Arquivos baixados em: {path}")
    except Exception as e:
        raise ConnectionError(f"Erro no download: {e}")

    csv_files = glob.glob(f"{path}/*.csv")
    if not csv_files:
        raise FileNotFoundError("Nenhum CSV encontrado.")
    
    csv_path = csv_files[0]
    
    # Cria ou Atualiza o registro do Dataset
    if not existing_dataset:
        dataset = KaggleDataset(
            kaggle_id=kaggle_dataset_id,
            title=kaggle_dataset_id.split("/")[-1],
            local_path=path,
            status="downloading"
        )
        db.add(dataset)
        db.commit()
        db.refresh(dataset)
    else:
        dataset = existing_dataset

    # LÃª CSV e Salva no Staging
    df = pd.read_csv(csv_path)
    df = df.where(pd.notnull(df), None)
    records = df.to_dict(orient="records")
    total = len(records)
    
    print(f"ğŸ’¾ Salvando {total} registros brutos no banco...")
    
    staging_objects = []
    for row in records:
        staging_objects.append(
            KaggleStaging(dataset_id=dataset.id, data=row, processed=False)
        )
    
    db.bulk_save_objects(staging_objects)
    
    dataset.record_count = total
    dataset.status = "ready"
    db.commit()
    
    print("âœ… Carga no Staging concluÃ­da.")
    return dataset.id